<!DOCTYPE html>
<html lang="en" data-theme="light">

<head>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aria Ghora Prabono</title>

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Rubik:ital,wght@0,400;0,700;1,400;1,700&display=swap"
        rel="stylesheet">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/picocss/1.5.2/pico.min.css"
        integrity="sha512-3gFq2IXMVlAQaUyahzhjDRivv0yqyXTb7xiy6ivTaG5Uz4hKI54uYxpQefdomgDVQ11eJVUbXG0YdPMDISiGgg=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />

    <!-- Syntax highlighting -->
    <link rel="stylesheet" href="https://unpkg.com/highlightjs@9.16.2/styles/a11y-light.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>
        hljs.highlightAll();
    </script>

    <script src="/js/asciinema-player.min.js"></script>
    <link rel="stylesheet" href="/css/asciinema-player.css">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
        integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
        crossorigin="anonymous"></script>
    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
        integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
        integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [{
                    left: '$$',
                    right: '$$',
                    display: true
                }, {
                    left: '$',
                    right: '$',
                    display: false
                }, {
                    left: '\\(',
                    right: '\\)',
                    display: false
                }, {
                    left: '\\[',
                    right: '\\]',
                    display: true
                }],
                // • rendering keys, e.g.:
                throwOnError: false,
            });
        });
    </script>

    <!-- Custom CSS and JS -->
    <link rel="stylesheet" href="/css/style.css">
    <script src="/js/main.js"></script>

</head>

<body>
    <div class="container">
        <div class="content">
            <div class="navbar">
                <a href="/index.html">Home</a> /
                <a href="/now.html">Now</a> /
                <a href="/notes/">Notes</a> /
                <a href="/about.html">About</a> /
                <!-- <a href="/others.html">Others</a> - -->
                <a href="/friends.html">Friends</a>
            </div><h1>Pengenalan digit tertulis pada formulir C1-Plano (bagian 1: pra-pemrosesan citra)</h1>
<p>Pemilihan umum (pemilu) Indonesia 2024 melibatkan sistem rekapitulasi berbasis mobile yang secara otomatis melakukan pengenalan karakter (digit) tertulis atau <em>optical character recognition</em> (OCR) untuk mempercepat diseminasi hasil hitung.
Kendati sudah ada beberapa pihak yang mengupas metodenya melalui proses <em>reverse engineering</em> aplikasi sirekap, di tulisan ini saya akan mencoba melakukan OCR dengan sentuhan interpretasi saya pribadi.</p>
<p>Tulisan ini bersifat pedagogis dengan menunjukkan teknik-teknik sederhana dan alat yang umum (Python dengan beberapa pustakanya) yang dapat digunakan untuk permasalahan pengenalan digit.
Walau hasil akhirnya akan berkualitas purwarupa (<em>prototype</em>), dengan cukup kreatifitas pembaca dapat mengembangkannya sendiri.
Misalnya, dengan mengulangi langkah-langkahnya untuk pengembangan di <em>platform</em> mobile.</p>
<h2>Memahami layout formulir C1-Plano</h2>
<p>Gambar di bawah ini adalah contoh formulir C1-Plano untuk Pemilu 2024.
Formulir ini menyediakan ruang khusus untuk mencatat perhitungan suara melalui turus dan hasil rekapitulasi.
Selain mencantumkan angka hasil hitungan, formulir ini juga memiliki area arsiran yang disesuaikan dengan angka hasil perhitungan.</p>
<img src="img/contoh-c1.jpeg" width=400/>
<p class="caption">Contoh formulir C1-Plano (<a href="https://pemilu2024.kpu.go.id/pilpres/hitung-suara/31/3171/317106/3171061001/3171061001010">sumber</a>) </p>
<h2>Permasalahan citra formulir C1-Plano</h2>
<p>Untuk proses OCR, kita hanya perlu area penting saja (<em>region of interest</em> atau RoI), yaitu bagian angka hasil hitung masing-masing paslon sisi pinggir kanan, kolom &quot;jumlah suara sah&quot;.
Idealnya, kita potong saja area angka pada foto formulir tersebut, ambil digit-digitnya sesuai dengan koordinat tertentu, dan lakukan klasifikasi dengan suatu model <em>machine learning</em>.
Namun, sepertinya tidak akan semudah itu.
Ada beberapa masalah yang akan ditemui di hasil foto C1-Plano, setidaknya, antara lain:</p>
<ol>
<li>Perbedaan sudut pandang/perspektif pengambilan gambar, sehingga hasil nampak miring</li>
<li>Pencahayaan yang tidak konsisten karena tidak ada standarisasi teknis alat pengambilan gambar</li>
<li>Perbedaan kualitas gambar, karena beda tempat pemungutan suara (TPS) kemungkinan beda pula kamera yang digunakan panitia</li>
<li><em>Occlusion</em>, yaitu adanya bagian pada gambar yang terhalangi objek lain, misalnya gambar terhalangi tangan orang lain saat pengambilan gambar</li>
<li>Inkonsistensi penulisan digit tiap orang</li>
</ol>
<p>Permasalahan 1 - 4 akan diselesaikan pada tahap pra-pemrosesan dengan menggunakan beberapa teknik pengolahan citra digital.
Untuk permasalahan 5, saya akan mengandalkan teknik <em>machine learning</em> dengan model <em>neural network</em>.
Solusi permasalahan 5 akan dipaparkan pada tulisan bagian kedua.</p>
<h2>Pra-pemrosesan citra (<em>image preprocessing</em>)</h2>
<p>Tahap pertama adalah pra-pemrosesan.
Kita akan bekerja dengan citra dalam skala abu-abu (<em>grayscale image</em>) dan biner karena informasi warna tidak terlalu penting.
Oleh karenanya, perlu dilakukan konversi citra berwarna ke <em>grayscale</em> jika dibutuhkan.
Hasil akhir yang diharapkan di tahap ini adalah RoI dengan distribusi keabuan dan kontras citra yang sudah ditingkatkan, dan perspektif yang diperbaiki, seperti berikut ini.</p>
<img src="img/deskewed.jpeg" width=400/>
<p class="caption">Hasil pra-pemrosesan</p>
<h3>Perbaikan kontras dengan teknik perataan histogram (<em>histogram equalization</em>)</h3>
<p>Citra formulir bisa dipastikan tidak selalu ideal.
Salah satu masalah utama yang ditemukan adalah buruknya kontras yang berakibat sulitnya pendeteksian garis dan komponen citra lainnya.
Untuk permasalahan ini, kita dapat menggunakan teknik perataan histogram<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.
Sederhananya, teknik ini akan menyebarkan intensitas keabuan secara merata sehingga bagian dengan kontras rendah bisa menjadi lebih tinggi.
Efek dari perataan histogram dicontohkan oleh gambar di bawah ini.</p>
<img src="img/histeq.png" width=600/>
<p class="caption">Citra sebelum dan sesudah perataan histogram (<a href="https://id.wikipedia.org/wiki/Perataan_histogram">sumber</a>)</p>
<p>Perlu dicatat bahwa teknik perataan yang akan digunakan bukanlah perataan yang biasa, namun perataan histogram <strong>adaptif</strong>.
Tepatnya, saya akan menggunakan perataan histogram adaptif dengan pembatasan kontras, atau <em>contrast-limited adaptive histogram equalization</em> (CLAHE)<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.
Mengapa adaptif? Karena, dalam beberapa kasus, perataan histogram biasa bekerja pada seluruh citra sebagai satu unit.
Ini berarti bahwa perubahan yang dibuat pada histogram diterapkan secara seragam ke seluruh citra.
Di sisi lain, metode adaptif memungkinkan kita untuk melakukan perataan histogram berdasarkan bagian-bagian lebih kecil dari citra, sehingga dapat menangkap konteks area yang lebih lokal.</p>
<p>Bagian pertama pra-pemrosesan ini dapat dibuat dengan mudah sebagai berikut:</p>
<pre><code class="language-python">from typing import Tuple
import numpy as np
import cv2


def preprocess(gray_image: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
    gray_image = cv2.GaussianBlur(gray_image, (3, 3), 0)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(11,11))
    equalized = clahe.apply(gray_image)

    ...
</code></pre>
<h3>Pengambangan citra (<em>image thresholding</em>)</h3>
<p>Pengambangan citra digunakan untuk memisahkan objek dari latar belakangnya<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.
Teknik ini melibatkan konversi citra abu-abu menjadi citra biner, di mana pixel citra dikategorikan menjadi dua nilai intensitas (misalnya, hitam/putih) berdasarkan nilai ambang batas (threshold) tertentu.</p>
<p>Seperti perataan histogram, pengambangan citra juga bisa bekerja dalam model global dan adaptif.
Dalam pengambangan citra biasa, nilai ambang batas yang sama diterapkan secara seragam ke seluruh pixel citra.
Nilai ambang batas ini biasanya adalah nilai konstan yang dipilih berdasarkan analisis histogram citra atau kriteria tertentu.
Semua pixel dengan intensitas di atas ambang batas diatur ke nilai maksimal (misalnya, putih pada citra biner), dan pixel dengan intensitas di bawah ambang batas diatur ke nilai minimal (misalnya, hitam).
Pengambangan citra adaptif, seperti namanya, melibatkan pemilihan nilai ambang batas yang berbeda-beda untuk setiap wilayah atau piksel citra, berdasarkan karakteristik lokal citra tersebut.</p>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Example_of_adaptive_thresholding.png/836px-Example_of_adaptive_thresholding.png" width=600/>
<p class="caption">Pengambangan lokal vs adaptif (<a href="https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29">sumber</a>)</p>
<p>Metode adaptif lebih fleksibel dibandingkan dengan pengambangan citra biasa karena dapat menyesuaikan ambang batas secara lokal, memungkinkan untuk mengatasi variasi pencahayaan atau kontras yang ada di dalam citra.
Ini berguna terutama pada citra dengan pencahayaan yang tidak merata, di mana pengambangan global mungkin tidak efektif dalam memisahkan objek dari latar belakang di seluruh citra.
Oleh karena itu, saya akan menggunakan metode adaptif.
Kode fungsi <code>preprocess</code> dapat dilengkapi sebagai berikut.</p>
<pre><code class="language-python">def preprocess(gray_image: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
    gray_image = cv2.GaussianBlur(gray_image, (3, 3), 0)
    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(11,11))
    equalized = clahe.apply(gray_image)

    thresholded = cv2.adaptiveThreshold(
        equalized,
        255,
        cv2.ADAPTIVE_THRESH_MEAN_C,
        cv2.THRESH_BINARY_INV,
        15,
        15,
    )

    thresholded = cv2.erode(thresholded, np.ones((2, 2)), iterations=1)
    thresholded = cv2.dilate(thresholded, np.ones((2, 2)), iterations=2)

    return thresholded, equalized

</code></pre>
<p>Pengambagan adaptif yang saya gunakan berbasis <em>mean</em> (dengan argumen <code>cv2.ADAPTIVE_THRESH_MEAN_C</code>), yang berarti bahwa kita menggunakan nilai rerata dari pixel bertetanggaan sebagai nilai ambang batas.
Argumen <code>cv2.THRESH_BINARY_INV</code> berarti bahwa kita nilai pixel yang lebih besar daripada nilai ambang akan dianggap 0 (hitam), dan jika tidak, akan dianggap 255 (putih).
Ini bertujuan untuk menjadikan garis berwarna putih sebagai objek <em>foreground</em>, sekaligus mengikuti konvensi OpenCV yang menganggap putih sebagai <em>foreground</em>.</p>
<p>Saya akan menggunakan <a href="img/ref.jpeg">contoh citra formulir di tautan ini</a> sebagai contoh yang relatif mudah, tapi agak kurang ideal (sudut pandang agak miring).
Fungsi di atas jika diterapkan pada citra abu-abu formulir C1-Plano, akan menghasilkan citra terambangkan seperti berikut ini.</p>
<img src="img/thresholded.jpeg" width=350/>
<p class="caption">Hasil pengambangan </p>
<p>Tugas selanjutnya adalah mengambil satu persegi besar di tengah (pixel putih terhubung yang membentuk <em>quadrilateral</em>) yang berisi hasil penghitungan, dan membuang bagian putih selainnya.</p>
<h3>Ekstraksi RoI dan digit</h3>
<p>Pertama, lakukan analisis komponen terhubung.
Sebuah komponen terhubung dalam citra adalah kumpulan pixel yang terhubung satu sama lain melalui tetangganya dan memiliki properti serupa (misalnya, intensitas yang sama dalam citra biner).
Misalnya, suatu garis terbentuk dari beberapa pixel yang terhubung.
Dua pixel dianggap &quot;terhubung&quot; jika mereka berdekatan dan memenuhi kriteria tertentu (biasanya berdasarkan nilai piksel).</p>
<p>Ketika sebuah komponen terhubung ditemukan, semua piksel dalam komponen tersebut diberi label yang sama.
Ini dapat dilakukan menggunakan algoritma seperti <em>flood-fill</em> atau algoritma <em>two-pass</em>.
Setelah semua komponen terhubung dilabeli, atribut seperti ukuran, bentuk, atau posisi dapat diekstraksi untuk setiap komponen.</p>
<p>Komponen yang kita butuhkan (selanjutnya akan saya sebut sebagai <strong>komponen utama</strong>) diasumsikan memiliki tinggi yang lebih tinggi daripada $\frac 2 5$ kali tinggi citra, dan memiliki lebar lebih dari setengah lebar citra.
Tidak ada cara yang lebih baik daripada bereksperimen dengan mengganti nilai-nilai tersebut.</p>
<pre><code class="language-python">def get_main_component(binary_img: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
    labeled_image, n_labels = label(binary_img, connectivity=2, return_num=True)  # type: ignore

    valid = []
    height, width = binary_img.shape[:2]
    for i in range(1, n_labels + 1):
        _, _, h, w = component_rect(labeled_image, i)
        if h &gt; int(float(height) * (2.0 / 5.0)) and w &gt; width // 2:
            valid.append(i)
            break

    img = np.zeros((height, width))
    img[labeled_image == valid[0]] = 255  # Take only the valid component

    return img, labeled_image
</code></pre>
<p>Fungsi di atas digunakan pada citra yang sudah melalui proses pengambangan (luaran dari fungsi <code>preprocess</code>).
Jika berhasil menemukan komponen utama, hasilnya kurang lebih akan seperti berikut ini.</p>
<img src="img/main_component.jpeg" width=350/>
<p class="caption">Komponen utama yang terekstraksi</p>
<p><em>&quot;Kenapa tulisan-tulisan dan angka-angkanya hilang?&quot;</em></p>
<p>Tidak masalah. Nanti kita bisa kembalikan dari citra aslinya.
Yang kita butuhkan sekarang adalah sudut-sudut dari komponen utama, yang berguna untuk &quot;meluruskan&quot; kembali perspektif citra seperti yang akan dilakukan di langkah selanjutnya.</p>
<blockquote>
<p>Catatan: algoritma ini tidak sempurna (dan tidak akan mungkin bisa sempurna), sehingga bisa saja gagal dalam menemukan komponen utama. Sisanya adalah soal bagaimana kita pandai-pandai melakukan trik olah citra.</p>
</blockquote>
<h3>Mencari sudut-sudut terluar pada <em>quadrilateral</em> komponen utama</h3>
<p>Strategi unutk mencari sudut-sudut pada komponen utama cukup sederhana.
Misal $w$ adalah lebar citra dan $h$ adalah tinggi citra.
Dengan asumsi sumbu $Y$ positif ke arah bawah, maka:</p>
<ul>
<li>sudut <em>kiri atas</em> komponen utama adalah lokasi pixel putih yang terdekat dengan koordinat $(0,0)$</li>
<li>sudut <em>kanan atas</em> komponen utama adalah lokasi pixel putih yang terdekat dengan koordinat $(0,w)$</li>
<li>sudut <em>kiri bawah</em> komponen utama adalah lokasi pixel putih yang terdekat dengan koordinat $(h,0)$</li>
<li>sudut <em>kanan bawah</em> komponen utama adalah lokasi pixel putih yang terdekat dengan koordinat $(h,w)$</li>
</ul>
<p>Untuk memperkecil ruang pencarian masing-masing sudut, kita dapat membagi citra komponen utama menjadi empat kuadran.
Untuk tiap kuadran, cari sudut yang diinginkan.
Gambar di bawah mengilustrasikan proses ini.</p>
<img src="img/annotated.png" width=350/>
<p class="caption">Pencarian sudut-sudut <i>quadrilateral</i> komponen utama</p>
<pre><code class="language-python">def find_closest_pixel_to_point(
    pixel_coordiates: np.ndarray, reference_point: np.ndarray
) -&gt; np.ndarray:
    min_idx = ((pixel_coordiates - reference_point) ** 2).sum(1).argmin(0)
    return pixel_coordiates[min_idx]

def get_corners(component) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Find 4 pixel coordinates closest to each corner
    &quot;&quot;&quot;
    height, width = component.shape[:2]

    # top-left
    tl_coords = np.argwhere(component[: height // 2, : width // 2] == 255)
    tl_point = find_closest_pixel_to_point(tl_coords, np.array([0, 0]))

    # top-right
    tr_coords = np.argwhere(component[: height // 2, width // 2 :] == 255)
    tr_point = find_closest_pixel_to_point(tr_coords, np.array([0, width])) + np.array(
        [0, width // 2]
    )

    # bottom-left
    bl_coords = np.argwhere(component[height // 2 :, : width // 2] == 255)
    bl_point = find_closest_pixel_to_point(bl_coords, np.array([height, 0])) + np.array(
        [height // 2, 0]
    )

    # bottom-right
    br_coords = np.argwhere(component[height // 2 :, width // 2 :] == 255)
    br_point = find_closest_pixel_to_point(
        br_coords, np.array([height, width])
    ) + np.array([height // 2, width // 2])

    corners = np.array([tl_point, bl_point, tr_point, br_point])
    return corners
</code></pre>
<h3>Deskewing</h3>
<p>Setelah menemukan keempat sudut, kita dapat melakukan koreksi perspektif (<em>deskewing</em>).
Fungsi ini menggunakan citra asli dan koordinat empat titik yang menggambarkan sudut komponen utama yang terdistorsi.
Kemudian, fungsi ini menghitung matriks transformasi perspektif yang diperlukan untuk memetakan titik-titik ini ke lokasi baru yang menghasilkan citra dengan orientasi yang benar dan tanpa distorsi perspektif.
Matriks transformasi dihitung dengan menggunakan fungsi <code>cv2.getPerspectiveTransform</code>.</p>
<p>Penerapan transformasi dilakukan melalui cv2.warpPerspective, yang akan memanipulasi citra asli sesuai dengan matriks transformasi, memindahkan koordinat asli ke posisi baru.
Hasilnya adalah citra yang sudah dalam keadaan <em>deskewed</em> dengan proporsi yang seimbang, memperbaiki masalah kemiringan atau distorsi akibat perspektif yang kurang baik.</p>
<p>Matriks transformasi ini akan kita gunakan pada citra asli, sehingga bagian komponen utama dari citra tersebut akan &quot;dikembalikan&quot; dalam keadaan tegak lurus. Berikut implementasinya dalam Python:</p>
<pre><code class="language-python">def deskew(
    image: np.ndarray, src_coords: np.ndarray, dst_height: int, dst_width: int
) -&gt; np.ndarray:
    # target deskewing corners
    dst_coords = np.array(
        [[0, 0], [0, dst_height], [dst_width, 0], [dst_width, dst_height]]
    ).astype(np.float32)

    mat = cv2.getPerspectiveTransform(src_coords, dst_coords)
    result = cv2.warpPerspective(image, mat, (dst_width, dst_height))
    return result
</code></pre>
<p>Seluruh fungsi digunakan sebagai berikut:</p>
<pre><code class="language-python">if __name__ == &quot;__main__&quot;:
    # read image and preprocess
    img = cv2.imread(&quot;path/to/input_image.jpeg&quot;)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    thresholded, equalized = preprocess(gray)

    # get main component
    component, labeled = get_main_component(thresholded)

    # get corners of main component
    corners = get_corners(component).astype(np.float32)[:, ::-1]
    deskewed = deskew(equalized, corners, 600, 500)

    cv2.imwrite(&quot;path/to/output_image.jpeg&quot;, deskewed)
</code></pre>
<p>Dengan (beruntung dan) hasil sesuai harapan:</p>
<p><img src="img/deskewed.jpeg" alt=""></p>
<p>Jika RoI berhasil ditemukan, hasil <em>deskewing</em> akan relatif konsisten.
Berikut ini contoh beberapa hasil ekstraksi RoI, termasuk contoh deskewing yang gagal:</p>
<img src="img/collage.png"/>
<p class="caption">Beberapa contoh hasil ekstraksi RoI</p>
<p>Karena sudah mendapat hasil yang cukup konsisten, di titik ini seharusnya kita sudah bisa memotong area-area digit tertulis untuk dijadikan data latih model <em>machine learning</em> dan melakukan OCR.
Desain model <em>machine learning</em> dan proses-proses setelahnya akan dipaparkan di bagian kedua.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>https://id.wikipedia.org/wiki/Perataan_histogram&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>https://en.wikipedia.org/wiki/Adaptive_histogram_equalization&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>https://en.wikipedia.org/wiki/Thresholding_(image_processing)&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
<p class="footer">
  Copyright 2014-2024 Aria Ghora Prabono. Any and all opinions listed here are personal unless stated otherwise.
</p>
</div>


</div>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@9/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, htmlLabels: true, securityLevel: 'loose', theme: 'neutral'});
</script>

</body>

</html>
