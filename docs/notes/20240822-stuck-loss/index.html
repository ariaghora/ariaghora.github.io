<!doctype html>
<html lang="en" data-theme="light">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Aria Ghora Prabono</title>

        

        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Rubik:ital,wght@0,400;0,700;1,400;1,700&display=swap"
            rel="stylesheet"
        />

        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100..900&display=swap"
            rel="stylesheet"
        />

        <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/picocss/1.5.2/pico.min.css"
    integrity="sha512-3gFq2IXMVlAQaUyahzhjDRivv0yqyXTb7xiy6ivTaG5Uz4hKI54uYxpQefdomgDVQ11eJVUbXG0YdPMDISiGgg=="
    crossorigin="anonymous" referrerpolicy="no-referrer" /> -->

        <!-- Syntax highlighting -->
        <link
            rel="stylesheet"
            href="https://unpkg.com/highlightjs@9.16.2/styles/a11y-light.css"
        />
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
        <script>
            hljs.highlightAll();
        </script>

        <script src="/js/asciinema-player.min.js"></script>
        <link rel="stylesheet" href="/css/asciinema-player.css" />

        <!-- The loading of KaTeX is deferred to speed up page rendering -->
        <script
            defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
            integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
            crossorigin="anonymous"
        ></script>
        <!-- To automatically render math in text elements, include the auto-render extension: -->
        <script
            defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
            integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
            crossorigin="anonymous"
            onload="renderMathInElement(document.body);"
        ></script>
        <link
            rel="stylesheet"
            href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
            integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0"
            crossorigin="anonymous"
        />
        <script>
            document.addEventListener("DOMContentLoaded", function () {
                renderMathInElement(document.body, {
                    // customised options
                    // • auto-render specific keys, e.g.:
                    delimiters: [
                        {
                            left: "$$",
                            right: "$$",
                            display: true,
                        },
                        {
                            left: "$",
                            right: "$",
                            display: false,
                        },
                        {
                            left: "\\(",
                            right: "\\)",
                            display: false,
                        },
                        {
                            left: "\\[",
                            right: "\\]",
                            display: true,
                        },
                    ],
                    // • rendering keys, e.g.:
                    throwOnError: false,
                });
            });
        </script>

        <!-- Custom CSS and JS -->
        <link rel="stylesheet" href="/css/style.css" />
        <script src="/js/main.js"></script>
    </head>

    <body>
        <div class="container">
            <div class="content">
                <div class="navbar">
                    <a href="/index.html">Home</a> /
                    <a href="/about.html">About</a> /
                    <a href="/now.html">Now</a> / 
                    <a href="/notes/">Notes</a> /
                    <a href="/til/">TIL</a> /
                    <a href="/snippets/">Snippets</a> /
                    <!-- <a href="/others.html">Others</a> - -->
                    <a href="/friends.html">Friends</a>
                </div>
            </div>
<h1>Diagnosing stuck loss in neural networks: cross-entropy and random guessing</h1>
<p>I recently trained a custom neural net model and wondered why the loss was stuck at a certain value.
For more context, I trained the model to predict 5 classes, and the loss value where it got stuck was around $1.6$.
Upon inspecting the model thoroughly, I noticed that the model was only slightly better than (if not equal to) a random guess.</p>
<p>Apparently, we can diagnose this behavior early during training just by inspecting the loss value and the number of classes, provided that we use the standard cross-entropy loss function.
The cross-entropy loss for a single sample is defined as</p>
<p>\begin{equation}
L = -\sum_{i=1}^{K} y_i\log(p_i)
\end{equation}</p>
<p>where $y_i$ is the true distribution and one-hot encoded in most cases ($y_i=1$ for the correct class and $y_i=0$ for the other classes) and $p_i$ is the predicted probability for class $i$.
Suppose the <strong>true</strong> class is $j$. Since $y_i$ is 1 for the correct class $j$ (i.e., when $y_i=y_j$) and 0 for all other classes, then</p>
<p>\begin{equation}
\begin{aligned}
L &amp;= -(0+\dots+0+y_j\cdot\log(p_j)+0+\dots+0) \\
&amp;= -y_j \cdot \log(p_j) \\
&amp;= -\log(p_j).
\end{aligned}
\end{equation}</p>
<p>Since the model is guessing randomly, also assuming that the class is well-balanced, then the probability for it to give correct predicted class (the $p_j$) over $K$ classes is uniform, i.e., $\frac 1 K$.
Now, substituting $p_j$ with $\frac 1 K$, we have the so-called $L_{rand}$ to denote loss for random guess.</p>
<p>\begin{equation}
\begin{aligned}
L_{rand} &amp;= -\log\left(\frac 1 K\right)\\
&amp;= -(\log(1)-\log(K))\\
&amp;= \log(K).
\end{aligned}
\end{equation}</p>
<blockquote>
<p>You may consider another probability mass function when the class is imbalanced for a better assumption.</p>
</blockquote>
<p>I use PyTorch. For some reason, in PyTorch, the cross-entropy is implemented based on the natural logarithm, so we can replace $\log(K)$ in the equations above with $\ln(K)$.
Quick checking using my calculator app, I got $\ln(5)=1.6094379124341$, which is consistent with the value I obtained before.
Yeah, it's a random-guess grade model.</p>
<p><strong>Key takeaway:</strong> when training a neural net classifier, aim for loss values smaller than $\ln(K)$.
Ideally we want as close as possible to zero, but take $\ln(K)$ as your hard threshold.
Smaller than that, you're in the right direction.
Larger than that, there must be something wrong with your training setup.</p>
<p class="footer">
<pre>



■────────────────────────────────────────────────────────────────────■
│                                                                    │
│ Copyright 2014-2024 Aria Ghora Prabono. Any and all opinions       │
│ listed here are personal unless stated otherwise.                  │
│                                                                    │
■────────────────────────────────────────────────────────────────────■
</pre>
</p>
</div>


</div>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@9/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, htmlLabels: true, securityLevel: 'loose', theme: 'neutral'});
</script>

</body>

</html>
