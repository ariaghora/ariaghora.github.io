<!doctype html>
<html lang="en" data-theme="light">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Aria Ghora Prabono</title>

        

        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Rubik:ital,wght@0,400;0,700;1,400;1,700&display=swap"
            rel="stylesheet"
        />

        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100..900&display=swap"
            rel="stylesheet"
        />

        <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/picocss/1.5.2/pico.min.css"
    integrity="sha512-3gFq2IXMVlAQaUyahzhjDRivv0yqyXTb7xiy6ivTaG5Uz4hKI54uYxpQefdomgDVQ11eJVUbXG0YdPMDISiGgg=="
    crossorigin="anonymous" referrerpolicy="no-referrer" /> -->

        <!-- Syntax highlighting -->
        <link
            rel="stylesheet"
            href="https://unpkg.com/highlightjs@9.16.2/styles/a11y-light.css"
        />
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
        <script>
            hljs.highlightAll();
        </script>

        <script src="/js/asciinema-player.min.js"></script>
        <link rel="stylesheet" href="/css/asciinema-player.css" />

        <!-- The loading of KaTeX is deferred to speed up page rendering -->
        <script
            defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
            integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
            crossorigin="anonymous"
        ></script>
        <!-- To automatically render math in text elements, include the auto-render extension: -->
        <script
            defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
            integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
            crossorigin="anonymous"
            onload="renderMathInElement(document.body);"
        ></script>
        <link
            rel="stylesheet"
            href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
            integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0"
            crossorigin="anonymous"
        />
        <script>
            document.addEventListener("DOMContentLoaded", function () {
                renderMathInElement(document.body, {
                    // customised options
                    // • auto-render specific keys, e.g.:
                    delimiters: [
                        {
                            left: "$$",
                            right: "$$",
                            display: true,
                        },
                        {
                            left: "$",
                            right: "$",
                            display: false,
                        },
                        {
                            left: "\\(",
                            right: "\\)",
                            display: false,
                        },
                        {
                            left: "\\[",
                            right: "\\]",
                            display: true,
                        },
                    ],
                    // • rendering keys, e.g.:
                    throwOnError: false,
                });
            });
        </script>

        <!-- Custom CSS and JS -->
        <link rel="stylesheet" href="/css/style.css" />
        <script src="/js/main.js"></script>
    </head>

    <body>
        <div class="container">
            <div class="content">
                <div class="navbar">
                    <a href="/index.html">Home</a> /
                    <a href="/about.html">About</a> /
                    <a href="/now.html">Now</a> / 
                    <a href="/notes/">Notes</a> /
                    <a href="/til/">TIL</a> /
                    <a href="/snippets/">Snippets</a> /
                    <!-- <a href="/others.html">Others</a> - -->
                    <a href="/friends.html">Friends</a>
                </div>
            </div>
<h1>Neural network runtime dengan C</h1>
<p>Dunia ideal saya soal <em>machine learning deployment</em> adalah distribusi seminimal mungkin.
Minimal dua file: file executable dan file berisi parameter model yang sudah dilatih.
Cara <em>mainstream</em> adalah distribusikan proyek berikut dengan interpreter Python.</p>
<h2>Yang rumit adalah melatih NN, inferensi (mungkin) tidak</h2>
<p>Membuat pustaka NN lengkap yang mengakomodasi proses latih dan inferensi.</p>
<p>Untuk melatih model, pustaka modern menyediakan fitur <em>autograd</em>, yaitu pengihtungan gradien otomatis.
Ini berguna untuk memperbarui paramter model selama proses belajar.
Selain itu, proses komputasi juga harus cepat. Ini membutuhkan optimasi di sana-sini, yang membutuhkan upaya yang sangat... monumental.</p>
<p>Objektif proyek:</p>
<blockquote>
<p>Ekspor parameter model NN (baik <em>pretrained</em> maupun hasil latih sendiri), muat dalam program C, gunakan untuk inferensi.</p>
</blockquote>
<h2>Saya menggunakan C</h2>
<p>Pertanyaan yang pasti muncul:</p>
<blockquote>
<p>Mengapa C? Bukankah Julia bisa? Bukanlah Rust juga bisa?</p>
</blockquote>
<ul>
<li>Karena C minimalis, tidak butuh toolchain yang terlalu besar. Toolchain yang minimalis buat saya <em>sparks joy</em>✨. Jika mau, kita bisa pakai salah satu compiler C terkecil, <a href="">tcc</a>.</li>
<li>Karena C adalah <em>lingua franca</em>: fungsi yang ditulis di C dapat dipanggil di bahasa lain, dan yang terpenting, saya bisa menyasar microcontroller (yang juga merupakan salah satu target saya nanti).</li>
<li>Saya <s>masokis</s> merasa tertantang.</li>
<li>For fun.</li>
</ul>
<h2>NN hanyalah soal operasi tensor, dan pada praktiknya, tensor hanyalah <em>byte array</em></h2>
<p>Model NN, sekecil atau sebesar apapun itu, hanyalah seonggok angka-angka yang hanya berguna dengan operasi aritmatika.
Suatu model NN dengan satu <em>hidden layer</em> $relu(\mathbf{x}\mathbf{w}_1+\mathbf{b}_1)\mathbf{w}_2+\mathbf{b}_2$</p>
<pre><code class="language-python">from torch.nn import Sequential, Linear, ReLU

model = Sequential(
    Linear(3, 5),
    ReLU(),
    Linear(5, 2),
)

print(model)


&quot;&quot;&quot; Output:

Sequential(
  (0): Linear(in_features=3, out_features=5, bias=True)
  (1): ReLU()
  (2): Linear(in_features=5, out_features=2, bias=True)
)

&quot;&quot;&quot;
</code></pre>
<pre><code class="language-python">print(model[0].weight.detach().numpy(), &quot;\n&quot;)
print(model[0].bias.detach().numpy(), &quot;\n&quot;)
print(model[2].weight.detach().numpy(), &quot;\n&quot;)
print(model[2].bias.detach().numpy(), &quot;\n&quot;)


&quot;&quot;&quot; Output:

[[-0.05593944  0.45469582  0.28000206]
 [ 0.3861447  -0.25333872 -0.46768567]
 [-0.25107583 -0.17574829 -0.46110478]
 [ 0.3162706   0.3284096  -0.5111614 ]
 [ 0.36777872  0.38549262  0.45413244]] 

[ 0.4335612   0.53432095 -0.5666646   0.50835824  0.46640122] 

[[ 0.2071963   0.18049729  0.44086027  0.39566457 -0.22345108]
 [ 0.22607613  0.33495134  0.27171385 -0.00866625 -0.2844745 ]] 

[0.3454901 0.0193561] 

&quot;&quot;&quot;
</code></pre>
<h2>Strategi mengekspor tensor</h2>
<p>Seluruh informasi tensor yang dibutuhkan akan disimpan sebagai byte array.
Sebagai ilustrasi, kita memiliki tensor (<code>np.ndarray</code>) berdimensi 2 (atau <code>x.ndim == 2</code>) dan ukuran $3 \times 5$ (atau <code>x.shape == (3, 5)</code>).</p>
<p>Penataan data tensor tersebut dalam format byte array adalah sebagai berikut:</p>
<ul>
<li>Bagian pertama adalah informasi jumlah dimensi tensor (<code>ndim</code>) yang direpresentasikan dengan integer (4 byte). Maka, 4 byte pertama pada byte array digunakan untuk menyimpan <code>ndim</code> bernilai 2.</li>
<li>Empat byte setelahnya menampung angka 3 (ukuran dimensi pertama), kemudian empat byte setelahnya lagi menampung angka 5 (ukuran dimensi kedua).</li>
<li>Setelahnya, barulah kita meletakkan seluruh data tensor itu sendiri sebagai array yang diratakan (<em>flatten</em>, sebagai array 1 dimensi).</li>
</ul>
<p>Berikut ini ilustrasinya:</p>
<p><img src="penataan_data.png" alt="Penataan metadata dan data tensor"></p>
<p class="caption">Penataan metadata dan data tensor</p>
<p>Kita bisa dengan mudah melakukan hal ini dengan NumPy seperti berikut ini.</p>
<pre><code class="language-python">import numpy as np
from io import BufferedWriter


def dump_ndarray(x: np.ndarray, f: BufferedWriter):
    x = np.ascontiguousarray(x, dtype=np.float32)
    # Secara berurutan, tuliskan  ndim, shape, data tensor
    np.array(x.ndim, dtype=np.int32).tofile(f)
    np.array(x.shape, dtype=np.int32).tofile(f)
    f.write(x.tobytes())

x = np.array(
    [[1, 2, 3], 
     [4, 5, 6],
     [1, 2, 3],
     [4, 5, 6],
     [1, 2, 3]]
)

with open(&quot;x.dat&quot;, &quot;wb&quot;) as f:
    dump_ndarray(x, f)
</code></pre>
<p>Tipe data <code>np.int32</code> (setara dengan <code>int</code> pada C) dan <code>np.float32</code> (setara dengan <code>float</code> pada C) sama-sama berukuran 4 byte. Secara default numpy menggunakan <em>big <a href="https://en.wikipedia.org/wiki/Endianness">endian</a></em> untuk urutan byte.
Jika <code>x.dat</code> dibuka dengan <em>hex editor</em>, maka kontennya kurang lebih akan seperti ini:</p>
<p><img src="hex_editor.png" alt="tensor yang sudah disimpan dibuka dengan hex editor"></p>
<h3>Representasi tensor pada C</h3>
<p>Saya pikir, pustaka tensor seperti PyTorch dan NumPy memiliki tiga komponen utama: data, bentuk, dan jumlah dimesi.
Operasi-operasi seperti parkalian matriks dan konvolusi dapat dilakukan cukup dengan mengetahui ketiganya.
Berikut ini cara saya merepresentasikan struktur data tensor pada C:</p>
<pre><code class="language-C">#define NNRT_FLOAT float

typedef struct {
    NNRT_FLOAT *data;
    int *shape;
    int ndim;
} nnrt_Tensor;
</code></pre>
<pre><code class="language-C">nnrt_Tensor *nnrt_tensor_fread(FILE *fp) {
    nnrt_Tensor *tensor = (nnrt_Tensor *)malloc(sizeof(nnrt_Tensor));

    fread(&amp;tensor-&gt;ndim, sizeof(int), 1, fp);

    tensor-&gt;shape = (int *)malloc(tensor-&gt;ndim * sizeof(int));
    fread(tensor-&gt;shape, sizeof(int), tensor-&gt;ndim, fp);

    size_t sz = nnrt_tensor_size(tensor);

    tensor-&gt;data = (NNRT_FLOAT *)malloc(sz * sizeof(NNRT_FLOAT));
    fread(tensor-&gt;data, sizeof(NNRT_FLOAT), sz, fp);

    return tensor;
}
</code></pre>
<h2><em>Multi-layer perceptron</em></h2>
<p>Setelah mekanisme memuat tensor di C sudah dibuat, yang tersisa (banyak) selanjutnya adalah membuat fungsi-fungsi untuk kebutuhan inferensi.
Sebelumnya, saya akan membuat <em>classifier</em> sederhana menggunakan <code>MLPClassifier</code> dari pustaka <code>scikit-learn</code>.
<code>MLPClassifier</code> adalah kelas untuk membuat <em>fully-connected NN</em> dengan mudah.</p>
<pre><code class="language-python">from sklearn.datasets import load_iris
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import MinMaxScaler

from dump import dump_ndarray_list


def dump_ndarray_list(ndarray_list: List[np.ndarray], filename: str) -&gt; None:
    with open(filename, &quot;wb&quot;) as f:
        for x in ndarray_list:
            dump_ndarray(x, f)


x, y = load_iris(return_X_y=True)
y = y.ravel()
x = MinMaxScaler().fit_transform(x)

# MLP dengan 2 hidden layer
clf = MLPClassifier(hidden_layer_sizes=(100, 20), max_iter=1000).fit(x, y)

# clf.coefs_ adalah list yang berisi 3 ndarray, 2 untuk parameter hidden layer
# dan 1 untuk parameter output layer.
# clf.intercepts_ juga list berisi 3 ndarray untuk bias.
all_params = clf.coefs_ + [i.reshape(1, -1) for i in clf.intercepts_]

# Kita ekspor semua tensor secara sekuensial, semua data tensor
# saling bersebelahan
dump_ndarray_list(all_params, &quot;mlp.dat&quot;)
</code></pre>
<p>Parameter yang sudah dilatih disimpan pada atribut <code>coefs_</code> (bobot $\mathbf{w}$) dan <code>intercept_</code> (bias $\mathbf{b}$).
Semuanya bertipe <code>np.ndarray</code>.
Keuntungan fungsi <code>dump_ndarray()</code> dia atas adalah, selama tensor (dari pustaka apapun) berupa <code>np.ndarray</code> atau setidaknya bisa dikonversi menjadi <code>np.ndarray</code>, kita bisa mengekspornya.</p>
<p>Ini termasuk model MLPClassifier</p>
<div class="toggle">
<pre><code class="language-C">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

#include &quot;../nnrt.h&quot;

int main(void) {
    // Sample of min-max scaled of iris dataset
    float x_data[] = {
        0.22222222, 0.62500000, 0.06779661, 0.04166667,  // -&gt; 0
        0.16666667, 0.41666667, 0.06779661, 0.04166667,  // -&gt; 0
        0.61111111, 0.41666667, 0.71186441, 0.79166667,  // -&gt; 2
        0.52777778, 0.58333333, 0.74576271, 0.91666667   // -&gt; 2
    };
    nnrt_Tensor *x = nnrt_tensor_alloc(2, (int[]){4, 4});
    memcpy(x-&gt;data, x_data, 16 * sizeof(float));

    // Load trained parameters
    char *filename = &quot;mlp.dat&quot;;
    FILE *fp = fopen(filename, &quot;rb&quot;);
    if (!fp) {
        printf(&quot;Cannot load weight\n&quot;);
        exit(1);
    }
    nnrt_Tensor *w1 = nnrt_tensor_fread(fp);
    nnrt_Tensor *w2 = nnrt_tensor_fread(fp);
    nnrt_Tensor *w3 = nnrt_tensor_fread(fp);
    nnrt_Tensor *b1 = nnrt_tensor_fread(fp);
    nnrt_Tensor *b2 = nnrt_tensor_fread(fp);
    nnrt_Tensor *b3 = nnrt_tensor_fread(fp);
    fclose(fp);

    // Hidden layer 1
    nnrt_Tensor *h1 = nnrt_tensor_alloc(2, (int[]){4, 100});
    nnrt_affine(x, w1, b1, h1);
    nnrt_relu(h1, h1);

    // Hidden layer 2
    nnrt_Tensor *h2 = nnrt_tensor_alloc(2, (int[]){4, 20});
    nnrt_affine(h1, w2, b2, h2);
    nnrt_relu(h2, h2);

    // Output layer
    nnrt_Tensor *out = nnrt_tensor_alloc(2, (int[]){4, 3});
    nnrt_affine(h2, w3, b3, out);
    nnrt_relu(out, out);

    //// optionally, calculate softmax
    // nnrt_softmax(out, 1, out);

    // Get labels
    nnrt_Tensor *lbl = nnrt_tensor_alloc(2, (int[]){4, 1});
    nnrt_argmax(out, 1, lbl);

    printf(&quot;Labels:\n&quot;);
    for (size_t i = 0; i &lt; 4; i++)
        printf(&quot;%f\n&quot;, lbl-&gt;data[i]);

    // Free params 
    nnrt_tensor_free(x);
    nnrt_tensor_free(w1);
    nnrt_tensor_free(w2);
    nnrt_tensor_free(w3);
    nnrt_tensor_free(b1);
    nnrt_tensor_free(b2);
    nnrt_tensor_free(b3);

    // Free intermediary variables
    nnrt_tensor_free(h1);
    nnrt_tensor_free(h2);
    nnrt_tensor_free(out);
    nnrt_tensor_free(lbl);

    return 0;
}

</code></pre>
</div>
<p class="footer">
<pre>



■────────────────────────────────────────────────────────────────────■
│                                                                    │
│ Copyright 2014-2024 Aria Ghora Prabono. Any and all opinions       │
│ listed here are personal unless stated otherwise.                  │
│                                                                    │
■────────────────────────────────────────────────────────────────────■
</pre>
</p>
</div>


</div>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@9/dist/mermaid.esm.min.mjs'; mermaid.initialize({startOnLoad: true, htmlLabels: true, securityLevel: 'loose', theme: 'neutral'});
</script>

</body>

</html>
